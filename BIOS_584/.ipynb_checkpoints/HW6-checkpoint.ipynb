{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW6 (20')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size='4'>\n",
    "    \n",
    "Please submit your assignment as an HTML or PDF file.\n",
    "\n",
    "Print your name (First and Last) below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiyamika Williams\n"
     ]
    }
   ],
   "source": [
    "# Write your answer here:\n",
    "print('Tiyamika Williams')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size='4'>\n",
    "    \n",
    "Import the `pandas`, `matplotlib.pyplot`, `numpy`, `scipy` libraries and assign them with proper nicknames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your answer here:\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not delete this code section.\n",
    "np.random.seed(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Write a function that output marginal summary statistics and missing values for continuous variable (10')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size='4'>\n",
    "\n",
    "**Write the function with `def`** (6')\n",
    "- Given a vector of continuous measure, you are asked to write a function named `fn_marginal_continuous`.\n",
    "- The function has one parameter `input_vec` and outputs a list of summary measure and the number of missing values.\n",
    "- Check the missingness of the `input_vec` using `np.isnan()` or `pd.isna()` functions.\n",
    "    - In our first case, we will assume the `input_vec` is an numpy array with missing values marked with `np.nan`.\n",
    "- The list of summary measure can be either **(mean, std)** or **(median, q1, q3)** depending on the normality assumption.\n",
    "    - To determine the normality assumption, you can rely on the p-value of the Shapiro-Wilk test.\n",
    "    - Relevant functions can be found here: https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.shapiro.html \n",
    "    - If the p-value < 0.05, it is not normally distributed, otherwise, you can treat it as normally distributed.\n",
    "    - Think about what measure to report based on the normality assumption.\n",
    "    - Part of relevant functions can be found here: https://numpy.org/doc/2.0/reference/generated/numpy.nanmean.html\n",
    "- The return statement should include two components: `missing_num` and `output_ls` (your summmary measure).\n",
    "    - The missing numbers should be of type `int` instead of `np.int64`, and summary values should be of type `float` instead of `np.float64`.\n",
    "    - Round all your summary values such that they have no more than **3** digits after the decimals. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_marginal_continuous(input_vec):\n",
    "    # Count missing values\n",
    "    missing_num = int(np.sum(np.isnan(input_vec)))\n",
    "    \n",
    "    # Remove missing values\n",
    "    clean_vec = input_vec[~np.isnan(input_vec)]\n",
    "    \n",
    "    # Shapiro-Wilk test\n",
    "    shapiro_stat, p_val = stats.shapiro(clean_vec)\n",
    "    \n",
    "    # If normal distribution: mean and std\n",
    "    if p_val >= 0.05:\n",
    "        mean_val = round(float(np.nanmean(clean_vec)), 3)\n",
    "        std_val = round(float(np.nanstd(clean_vec, ddof=1)), 3) \n",
    "        output_ls = [mean_val, std_val]\n",
    "        stat_names = [\"Mean\", \"Standard Deviation\"]\n",
    "        print(f\"Data is approximately normal (p = {p_val:.3f})\")\n",
    "    \n",
    "    # If not normal: median, Q1, Q3\n",
    "    else:  \n",
    "        median_val = round(float(np.nanmedian(clean_vec)), 3)\n",
    "        q1 = round(float(np.nanpercentile(clean_vec, 25)), 3)\n",
    "        q3 = round(float(np.nanpercentile(clean_vec, 75)), 3)\n",
    "        output_ls = [median_val, q1, q3]\n",
    "        stat_names = [\"Median\", \"Q1\", \"Q3\"]\n",
    "        print(f\"Data is not normal (p = {p_val:.3f})\")\n",
    "    \n",
    "    # Print labeled summary statistics\n",
    "    for name, value in zip(stat_names, output_ls):\n",
    "        print(f\"{name}: {value}\")\n",
    "\n",
    "    # Print missing value count\n",
    "    print(f\"Missing values: {missing_num}\")\n",
    "    \n",
    "    # Return both outputs\n",
    "    return missing_num, output_ls\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size='4'>\n",
    "\n",
    "**Test your function with the following different arguments:** (4') <br>\n",
    "For each scenario, please export the results as `missing_num_x`, `output_ls_x` and print them out separately.\n",
    "1. A standard normal random vector with a sample size of 100, named `input_vec_1`.\n",
    "2. A Chi-squared random vector with a degree of freedom 1 and a sample size of 100, named `input_vec_2`.\n",
    "3. Change the first element of `input_vec_1` as `np.nan` and create a new array named `input_vec_3`.\n",
    "    - Note that to create a copy of an numpy array, use `np.copy()` first.\n",
    "4. Change the last element of `input_vec_2` as `np.nan` and create a new array named `input_vec_4`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data is approximately normal (p = 0.614)\n",
      "Mean: -0.066\n",
      "Standard Deviation: 0.919\n",
      "Missing values: 0\n"
     ]
    }
   ],
   "source": [
    "# Write your own code for scenario 1:\n",
    "input_vec_1 = np.random.normal(loc=0, scale=1, size=100)\n",
    "missing_num_1, output_ls_1 = fn_marginal_continuous(input_vec_1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data is not normal (p = 0.000)\n",
      "Median: 0.314\n",
      "Q1: 0.043\n",
      "Q3: 0.934\n",
      "Missing values: 0\n"
     ]
    }
   ],
   "source": [
    "# Write your own code for scenario 2\n",
    "input_vec_2 = np.random.chisquare(df=1, size=100)\n",
    "missing_num_2, output_ls_2 = fn_marginal_continuous(input_vec_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data is approximately normal (p = 0.622)\n",
      "Mean: -0.067\n",
      "Standard Deviation: 0.924\n",
      "Missing values: 1\n"
     ]
    }
   ],
   "source": [
    "# Write your own code for scenario 3:\n",
    "input_vec_3 = np.copy(input_vec_1)\n",
    "input_vec_3[0] = np.nan\n",
    "missing_num_3, output_ls_3 = fn_marginal_continuous(input_vec_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data is not normal (p = 0.000)\n",
      "Median: 0.326\n",
      "Q1: 0.047\n",
      "Q3: 0.952\n",
      "Missing values: 1\n"
     ]
    }
   ],
   "source": [
    "# Write your own code for scenario 4:\n",
    "input_vec_4 = np.copy(input_vec_2)\n",
    "input_vec_4[-1] = np.nan\n",
    "missing_num_4, output_ls_4 = fn_marginal_continuous(input_vec_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Write a function that output marginal summary statistics and missing values for categorical variable (5')\n",
    "\n",
    "<font size='4'>\n",
    "\n",
    "**Write the function with `def`**\n",
    "- Given a column vector, you are asked to write a function named `fn_marginal_categorical`.\n",
    "- The function has one parameter named `input_vec` and outputs a list of summary measure and the number of missing values.\n",
    "- Check the missingness of the `input_vec` using `np.isnan()` or `pd.isna()` functions.\n",
    "    - In our second case, we will assume the `input_vec` is a column from a pandas DataFrame with missing values marked with `np.nan`.\n",
    "    - You can use both functions to identify missing values and yield the number of missingness.\n",
    "    - Use `pd.Series.value_counts()` function to obtain the frequency and proportion of `input_vec`, denoted as `tab_count` and `tab_percent`, respectively.\n",
    "    - Details can be found here: https://pandas.pydata.org/docs/reference/api/pandas.Series.value_counts.html\n",
    "    - For proportion, please use percentage (0-100%). You can ignore % when reporting.\n",
    "- The return statement should include two components: `missing_num` and `output_tab` (your summmary measure).\n",
    "    - For your `output_tab`, combine the count and proportion together using `pd.concat()`. Your `output_tab` should have three columns: variable name, count, and proportion.\n",
    "    - Details can be found here: https://pandas.pydata.org/docs/reference/api/pandas.concat.html\n",
    "    - The missing numbers should be of type `int` instead of `np.int64`, and percentgae values should be of type `float` instead of `np.float64`.\n",
    "    - Round all your relevant summary values such that they have no more than **2** digits after the decimals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your defined function in this code chunk only.\n",
    "def fn_marginal_categorical(input_vec):\n",
    "    # check missingness\n",
    "    missing_num = pd.isna(input_vec).sum()\n",
    "    missing_num = int(missing_num)\n",
    "    \n",
    "    # frequency and proportion\n",
    "    tab_count = input_vec.value_counts(dropna=True)\n",
    "    tab_percent = input_vec.value_counts(normalize=True, dropna=True) * 100\n",
    "    tab_percent = tab_percent.round(2)\n",
    "    \n",
    "    # combine the count and proportion together \n",
    "    output_tab = pd.concat([tab_count, tab_percent], axis=1).reset_index()\n",
    "    var_name = input_vec.name \n",
    "    output_tab.columns = [var_name, 'count', 'proportion']\n",
    "\n",
    "    #proper data type\n",
    "    output_tab['count'] = output_tab['count'].astype(int)\n",
    "    output_tab['proportion'] = output_tab['proportion'].astype(float)\n",
    "\n",
    "    #print results\n",
    "    print(f\"\\nSummary for variable: {var_name}\")\n",
    "    print(f\"Missing values: {missing_num}\\n\")\n",
    "    print(output_tab.to_string(index=False))\n",
    "\n",
    "    pass\n",
    "    return missing_num, output_tab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Test your written functions with a real dataset. (3')\n",
    "\n",
    "<font size='4'>\n",
    "    \n",
    "**Test the summary function for the continuous measure** (1')\n",
    "- Load the `PTSD dataset.xlsx` and name it as `ptsd_df`.\n",
    "    - The dataset should be stored under `data` folder when you sync changes and fetch origins the GitHub repository.\n",
    "- Use the column `pcl5month_score.baseline` as the input vector. This is a continuous measure.\n",
    "- Extract the corresponding column and give it a name `pcl5month_base`.\n",
    "- (*Optional*) You convert from a pandas.dataframe to an numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True /Users/tiyamikaw/PycharmProjects/BIOS-584/data/PTSD dataset.xlsx\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['record_id', 'ptsdpresent_caps', 'caps_minuspcl', 'caps_minuspcl_code',\n",
       "       'caps_intake', 'pcl5_score_intake', 'pcl5month_score.baseline',\n",
       "       'pcl5week_score.completion', 'pcl5month_score.3_month_follow_up',\n",
       "       'mdd_code',\n",
       "       ...\n",
       "       'state_code', 'va_benefits_indicator', 'wwp_alumni_indicator', 'army',\n",
       "       'airforce', 'marines', 'navy', 'coastguard', 'nationalguard',\n",
       "       'reserve'],\n",
       "      dtype='object', length=439)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import ptsd dataset in this code section only (no point for this part as you have done it a few times)\n",
    "current_dir = os.getcwd()\n",
    "full_dir = os.path.dirname(current_dir)\n",
    "ptsd_df = \"{}/data/PTSD dataset.xlsx\".format(full_dir)\n",
    "print(os.path.exists(ptsd_df), ptsd_df)\n",
    "ptsd_df = pd.read_excel(\n",
    "    ptsd_df,\n",
    "    sheet_name=\"main_dataset\")\n",
    "ptsd_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data is not normal (p = 0.000)\n",
      "Median: 51.0\n",
      "Q1: 42.0\n",
      "Q3: 62.0\n",
      "Missing values: 9\n",
      "Missing values: 9\n",
      "Summary statistics: [51.0, 42.0, 62.0]\n"
     ]
    }
   ],
   "source": [
    "# test continuous measure\n",
    "pcl5month_base = ptsd_df['pcl5month_score.baseline']\n",
    "missing_number_c, output_ls_c = fn_marginal_continuous(pcl5month_base)\n",
    "\n",
    "print(\"Missing values:\", missing_number_c)\n",
    "print(\"Summary statistics:\", output_ls_c)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size='4'>\n",
    "\n",
    "**Test the summary function for the categorical measure** (2')\n",
    "\n",
    "- Use the column `mdd_code` as the input vector. This is a binary vector.\n",
    "1. Extract the corresponding column and give it a name `mdd_code_vec`. Output your results as `missing_num_1` and `tab_1`. Print each element out (You will write `print()` twice).\n",
    "2. Create a copy of `mdd_code_vec` and name it as `mdd_code_vec_2`. Change its first element to `NaN`.\n",
    "    - Rerun the `fn_marginal_categorical()` with the new vector. Output your results as `missing_num_2` and `tab_2`. Print each element out (You will write `print()` twice)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary for variable: mdd_code\n",
      "Missing values: 0\n",
      "\n",
      " mdd_code  count  proportion\n",
      "        0    340       70.39\n",
      "        1    143       29.61\n"
     ]
    }
   ],
   "source": [
    "# Write your own code for scenario 1 only:\n",
    "mdd_code_vec= ptsd_df['mdd_code']\n",
    "missing_num_1, tab_1 = fn_marginal_categorical(mdd_code_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary for variable: mdd_code\n",
      "Missing values: 1\n",
      "\n",
      " mdd_code  count  proportion\n",
      "      0.0    339       70.33\n",
      "      1.0    143       29.67\n"
     ]
    }
   ],
   "source": [
    "# Write your own code for scenario 2 only:\n",
    "mdd_code_vec_2 = mdd_code_vec.copy()\n",
    "mdd_code_vec_2.iloc[0] = np.nan\n",
    "\n",
    "missing_num_2, tab_2 = fn_marginal_categorical(mdd_code_vec_2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Lambda functions and for loop (2')\n",
    "\n",
    "<font size='4'>\n",
    "\n",
    "- Create a ``` lambda ``` function that checks if column `pcl5_score_intake` is greater than 30, denoted as `fn_pcl5_ptsd_check`.\n",
    "- Create a new list `pcl5_score_intake_ls` that shows `True` if `pcl5_score_intake`>30 and `False` otherwise using a for loop.\n",
    "    - You can also try `map()` function to iterate the function over `pcl5_score_intake`.\n",
    "    - Syntax is simple: `map(function_name, iterable, ...)`. \n",
    "- Print out the number of patients with `pcl5_score_intake` over 30 and mark them as **Clinically Significant for PTSD**.\n",
    "    - Your output can be something like `XXX out of YYY patients (ZZZ%) were marked as clinically significant for PTSD.`\n",
    "    - Round your percentage with no more than **2** decimals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "451 out of 483 patients (93.37%) were marked as clinically significant for PTSD.\n"
     ]
    }
   ],
   "source": [
    "# Write your own code\n",
    "pcl5_score_intake = ptsd_df['pcl5_score_intake']\n",
    "\n",
    "fn_pcl5_ptsd_check = lambda x: x > 30\n",
    "pcl5_score_intake_ls = list(map(fn_pcl5_ptsd_check, pcl5_score_intake))\n",
    "num_significant = sum(pcl5_score_intake_ls)           \n",
    "total_patients = len(pcl5_score_intake_ls)\n",
    "percent_significant = round((num_significant / total_patients) * 100, 2)\n",
    "\n",
    "print(f\"{num_significant} out of {total_patients} patients ({percent_significant}%) were marked as clinically significant for PTSD.\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = \"5\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "45fc1f684f6f416f40889115beff3ddf69879b64cf4bfee48cb72a61e9d15d1a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
